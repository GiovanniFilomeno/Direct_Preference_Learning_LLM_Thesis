{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved at epoch 1 with val loss: 0.0810\n",
      "Epoch 1/150, Train Loss: 0.1031, Val Loss: 0.0810\n",
      "New best model saved at epoch 2 with val loss: 0.0793\n",
      "Epoch 2/150, Train Loss: 0.0888, Val Loss: 0.0793\n",
      "New best model saved at epoch 3 with val loss: 0.0766\n",
      "Epoch 3/150, Train Loss: 0.0835, Val Loss: 0.0766\n",
      "New best model saved at epoch 4 with val loss: 0.0745\n",
      "Epoch 4/150, Train Loss: 0.0806, Val Loss: 0.0745\n",
      "New best model saved at epoch 5 with val loss: 0.0690\n",
      "Epoch 5/150, Train Loss: 0.0774, Val Loss: 0.0690\n",
      "Epoch 6/150, Train Loss: 0.0755, Val Loss: 0.0720\n",
      "Epoch 7/150, Train Loss: 0.0738, Val Loss: 0.0700\n",
      "New best model saved at epoch 8 with val loss: 0.0679\n",
      "Epoch 8/150, Train Loss: 0.0723, Val Loss: 0.0679\n",
      "New best model saved at epoch 9 with val loss: 0.0679\n",
      "Epoch 9/150, Train Loss: 0.0710, Val Loss: 0.0679\n",
      "New best model saved at epoch 10 with val loss: 0.0613\n",
      "Epoch 10/150, Train Loss: 0.0700, Val Loss: 0.0613\n",
      "New best model saved at epoch 11 with val loss: 0.0596\n",
      "Epoch 11/150, Train Loss: 0.0688, Val Loss: 0.0596\n",
      "New best model saved at epoch 12 with val loss: 0.0552\n",
      "Epoch 12/150, Train Loss: 0.0677, Val Loss: 0.0552\n",
      "Epoch 13/150, Train Loss: 0.0667, Val Loss: 0.0575\n",
      "New best model saved at epoch 14 with val loss: 0.0548\n",
      "Epoch 14/150, Train Loss: 0.0649, Val Loss: 0.0548\n",
      "New best model saved at epoch 15 with val loss: 0.0524\n",
      "Epoch 15/150, Train Loss: 0.0638, Val Loss: 0.0524\n",
      "New best model saved at epoch 16 with val loss: 0.0522\n",
      "Epoch 16/150, Train Loss: 0.0631, Val Loss: 0.0522\n",
      "New best model saved at epoch 17 with val loss: 0.0495\n",
      "Epoch 17/150, Train Loss: 0.0626, Val Loss: 0.0495\n",
      "Epoch 18/150, Train Loss: 0.0613, Val Loss: 0.0507\n",
      "New best model saved at epoch 19 with val loss: 0.0476\n",
      "Epoch 19/150, Train Loss: 0.0603, Val Loss: 0.0476\n",
      "Epoch 20/150, Train Loss: 0.0605, Val Loss: 0.0509\n",
      "Epoch 21/150, Train Loss: 0.0593, Val Loss: 0.0484\n",
      "New best model saved at epoch 22 with val loss: 0.0457\n",
      "Epoch 22/150, Train Loss: 0.0583, Val Loss: 0.0457\n",
      "New best model saved at epoch 23 with val loss: 0.0456\n",
      "Epoch 23/150, Train Loss: 0.0578, Val Loss: 0.0456\n",
      "Epoch 24/150, Train Loss: 0.0578, Val Loss: 0.0466\n",
      "Epoch 25/150, Train Loss: 0.0562, Val Loss: 0.0484\n",
      "Epoch 26/150, Train Loss: 0.0555, Val Loss: 0.0460\n",
      "Epoch 27/150, Train Loss: 0.0558, Val Loss: 0.0482\n",
      "New best model saved at epoch 28 with val loss: 0.0371\n",
      "Epoch 28/150, Train Loss: 0.0495, Val Loss: 0.0371\n",
      "Epoch 29/150, Train Loss: 0.0482, Val Loss: 0.0390\n",
      "New best model saved at epoch 30 with val loss: 0.0351\n",
      "Epoch 30/150, Train Loss: 0.0476, Val Loss: 0.0351\n",
      "Epoch 31/150, Train Loss: 0.0474, Val Loss: 0.0372\n",
      "Epoch 32/150, Train Loss: 0.0474, Val Loss: 0.0363\n",
      "Epoch 33/150, Train Loss: 0.0462, Val Loss: 0.0381\n",
      "New best model saved at epoch 34 with val loss: 0.0349\n",
      "Epoch 34/150, Train Loss: 0.0465, Val Loss: 0.0349\n",
      "Epoch 35/150, Train Loss: 0.0459, Val Loss: 0.0359\n",
      "New best model saved at epoch 36 with val loss: 0.0329\n",
      "Epoch 36/150, Train Loss: 0.0460, Val Loss: 0.0329\n",
      "New best model saved at epoch 37 with val loss: 0.0322\n",
      "Epoch 37/150, Train Loss: 0.0458, Val Loss: 0.0322\n",
      "Epoch 38/150, Train Loss: 0.0452, Val Loss: 0.0327\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     99\u001b[39m epoch_train_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m x_better, x_worse, _ \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     x_better, x_worse = x_better.to(device), \u001b[43mx_worse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     optimizer.zero_grad()\n\u001b[32m    103\u001b[39m     loss = dpo_loss(model, x_better, x_worse)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys \n",
    "from maze_env import PolicyNetwork\n",
    "\n",
    "# Set device to MPS for Mac users, otherwise CPU\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Load the preference dataset\n",
    "df_preferences = pd.read_parquet(\"../tests/preferences.parquet\")\n",
    "\n",
    "# --- Split the dataset into train (90%), val (5%), and test (5%) ---\n",
    "train_df = df_preferences.sample(frac=0.90, random_state=42)\n",
    "temp_df = df_preferences.drop(train_df.index)\n",
    "val_df = temp_df.sample(frac=0.50, random_state=42)\n",
    "test_df = temp_df.drop(val_df.index)\n",
    "\n",
    "# Define the Preference Dataset class\n",
    "class PreferenceDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        # --- all'interno di PreferenceDataset --------------------\n",
    "        norm_stats_path = \"../tests/norm_stats.npz\" # Adatta il path se necessario\n",
    "        norm = np.load(norm_stats_path)\n",
    "        mean = norm[\"mean\"].astype(np.float32)\n",
    "        std  = norm[\"std\"].astype(np.float32) + 1e-8 # Aggiungi epsilon\n",
    "        self.x_better = ((df[[\"x_better\",\"y_better\"]].values - mean) / std).astype(np.float32)\n",
    "        self.x_worse  = ((df[[\"x_worse\", \"y_worse\"] ].values - mean) / std).astype(np.float32)\n",
    "        self.labels = df[\"preference\"].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.x_better[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.x_worse[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "# DPO loss function\n",
    "# def dpo_loss(model, x_better, x_worse):\n",
    "#     r_better = model(x_better)\n",
    "#     r_worse = model(x_worse)\n",
    "#     return -torch.mean(torch.log(torch.sigmoid(r_better - r_worse)))\n",
    "\n",
    "def dpo_loss(model, xb, xw, m=0.25):\n",
    "    return torch.clamp(m - (model(xb) - model(xw)), min=0).mean()\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "epochs = 150\n",
    "learning_rate = 1e-3\n",
    "hidden_dim = 256\n",
    "num_layers = 4\n",
    "dropout_prob = 0.05\n",
    "\n",
    "# Early stopping parameter\n",
    "early_stopping_patience = 10  # Number of epochs to wait before stopping if no improvement\n",
    "\n",
    "# Create Dataset objects for train, val, and test\n",
    "train_dataset = PreferenceDataset(train_df)\n",
    "val_dataset = PreferenceDataset(val_df)\n",
    "test_dataset = PreferenceDataset(test_df)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, optimizer, and scheduler\n",
    "model = PolicyNetwork(\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_layers=num_layers,\n",
    "    dropout_prob=dropout_prob\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3) #, verbose=True)\n",
    "\n",
    "# Track best validation loss for saving best model\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_count = 0  # Tracks epochs without improvement\n",
    "\n",
    "# Lists to store losses per epoch\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # --- Training Phase ---\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    for x_better, x_worse, _ in train_dataloader:\n",
    "        x_better, x_worse = x_better.to(device), x_worse.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = dpo_loss(model, x_better, x_worse)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x_better, x_worse, _ in val_dataloader:\n",
    "            x_better, x_worse = x_better.to(device), x_worse.to(device)\n",
    "            loss = dpo_loss(model, x_better, x_worse)\n",
    "            epoch_val_loss += loss.item()\n",
    "    avg_val_loss = epoch_val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    # Step the scheduler with the validation loss\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    # Check if this is the best validation loss so far; if so, save the model and reset patience\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"best_dpo_policy.pth\")\n",
    "        print(f\"New best model saved at epoch {epoch+1} with val loss: {avg_val_loss:.4f}\")\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if no_improvement_count >= early_stopping_patience:\n",
    "        print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "        break\n",
    "\n",
    "# --- Plot losses ---\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(train_losses, label=\"Training Loss\", color=\"blue\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\", color=\"orange\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ------------------\n",
    "# --- Test Phase ---\n",
    "# ------------------\n",
    "\n",
    "# Load the best saved model\n",
    "model.load_state_dict(torch.load(\"best_dpo_policy.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x_better, x_worse, _ in test_dataloader:\n",
    "        x_better, x_worse = x_better.to(device), x_worse.to(device)\n",
    "        r_better = model(x_better)\n",
    "        r_worse = model(x_worse)\n",
    "        # We consider the prediction correct if r_better > r_worse\n",
    "        correct += torch.sum(r_better > r_worse).item()\n",
    "        total += x_better.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test accuracy (with best model): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value range: -1.9788505 6.2813087\n"
     ]
    }
   ],
   "source": [
    "states = torch.rand(256, 2, device=device)\n",
    "with torch.no_grad():\n",
    "    v = model(states).cpu().numpy().squeeze()\n",
    "print(\"value range:\", v.min(), v.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmwTeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
