{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating preference pairs: 100%|██████████| 1999000/1999000 [1:54:41<00:00, 290.48it/s]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of preferences dataset completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Load the dataset and scores\n",
    "df_positions = pd.read_parquet(\"positions.parquet\")\n",
    "\n",
    "points = len(df_positions)\n",
    "\n",
    "# Score weights\n",
    "weight_path_distance = 9  # Highest weight for shortest path distance\n",
    "weight_dead_end = 0  # Penalize dead-ends\n",
    "weight_distance_to_goal = 3  # Distance to goal\n",
    "weight_distance_from_wall = 5  # Distance from walls\n",
    "\n",
    "# Function to evaluate the total score\n",
    "def compute_total_score(row):\n",
    "    return (\n",
    "        -weight_path_distance * row[\"path_distance\"] +\n",
    "        -weight_dead_end * row[\"is_dead_end\"] +\n",
    "        -weight_distance_to_goal * row[\"distance_to_goal\"] +\n",
    "        weight_distance_from_wall * row[\"distance_from_wall\"]\n",
    "    )\n",
    "\n",
    "# Adding column \"total_score\"\n",
    "df_positions[\"total_score\"] = df_positions.apply(compute_total_score, axis=1)\n",
    "\n",
    "# Generate preference pairs\n",
    "def generate_preference_pairs(df, num_pairs=50000):\n",
    "    pairs = set()  # Use a set to avoid duplicate pairs\n",
    "    with tqdm(total=num_pairs, desc=\"Generating preference pairs\") as pbar:\n",
    "        while len(pairs) < num_pairs:\n",
    "            # Randomly select two different records from the DataFrame\n",
    "            a, b = df.sample(n=2).to_dict(orient='records')\n",
    "            \n",
    "            # Determine which record has a higher total_score\n",
    "            better = a if a[\"total_score\"] > b[\"total_score\"] else b\n",
    "            worse = b if a[\"total_score\"] > b[\"total_score\"] else a\n",
    "            \n",
    "            # Create a preference pair (better x, better y, worse x, worse y, preference label)\n",
    "            pair = (better[\"x\"], better[\"y\"], worse[\"x\"], worse[\"y\"], 1)\n",
    "            \n",
    "            # Add the pair to the set if it is not already present\n",
    "            if pair not in pairs:\n",
    "                pairs.add(pair)\n",
    "                pbar.update(1)  # Update the progress bar only when a new pair is added\n",
    "    \n",
    "    return list(pairs)\n",
    "\n",
    "num_pairs = int(points * (points - 1)/2)\n",
    "# Generate preference pairs\n",
    "preference_pairs = generate_preference_pairs(df_positions, num_pairs=num_pairs)\n",
    "\n",
    "# Save the dataset\n",
    "df_preferences = pd.DataFrame(preference_pairs, columns=[\"x_better\", \"y_better\", \"x_worse\", \"y_worse\", \"preference\"])\n",
    "df_preferences.to_parquet(\"preferences.parquet\", index=False)\n",
    "\n",
    "print(\"Generation of preferences dataset completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pref_lern",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
