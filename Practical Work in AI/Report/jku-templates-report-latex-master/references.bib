@inproceedings{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
  booktitle={NeurIPS},
  year={2017}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and others},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@inproceedings{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and others},
  booktitle={NeurIPS},
  year={2020}
}

@article{rafailov2023direct,
  title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author={Rafailov, Rafael and others},
  journal={arXiv preprint arXiv:2305.18290},
  year={2023}
}

@article{schulman2017ppo,
  title={Proximal Policy Optimization Algorithms},
  author={Schulman, John and others},
  year={2017},
  journal={arXiv preprint},
  archivePrefix={arXiv},
  eprint={1707.06347}
}

@misc{filomeno2024seminar,
  title={Language Model Reward Alignment and Preference Optimization},
  author={Filomeno, Giovanni},
  year={2024},
  note={Seminar Report}
}

@inproceedings{kirk2024understanding,
  title={Understanding the Effects of RLHF on LLM Generalisation and Diversity},
  author={Kirk, Robert and others},
  booktitle={ICLR},
  year={2024}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and others},
  year={2022},
  journal={arXiv preprint},
  archivePrefix={arXiv},
  eprint={2203.02155}
}

@inproceedings{zhao2023slic,
  title={SLiC-HF: Sequence Likelihood Calibration with Human Feedback},
  author={Zhao, Yao and Joshi, Rishabh and Liu, Tianqi and Khalman, Misha and Saleh, Mohammad and Liu, Peter J.},
  booktitle={ICLR},
  year={2023}
}

@article{hejna2024contrastive,
  title={Contrastive Preference Learning: Learning From Human Feedback without RL},
  author={Hejna, Joey and Rafailov, Rafael and Ermon, Stefano and Finn, Chelsea},
  journal={ICLR},
  year={2024}
}

@article{azar2023ipo,
  title={A General Theoretical Paradigm to Understand Learning from Human Preferences},
  author={Azar, Mohammad Gheshlaghi and Rowland, Mark W. and Piot, Bilal and Guo, Daniel Z. and Calandriello, Daniele and Valko, Michal and Munos, RÃ©mi},
  journal={arXiv preprint arXiv:2310.12036},
  year={2023}
}
